{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from random import shuffle\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras import applications\n",
        "from keras import optimizers\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "hr5Jz8gn4NLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JMdGGEb3n1m"
      },
      "outputs": [],
      "source": [
        "train_real_path=\"data/CEDAR_genuine.npy\"\n",
        "train_fake_path=\"data/CEDAR_forg.npy\"\n",
        "syn_fake_path= \"data/cgan_CEDAR_forg.npy\"\n",
        "fake_sample=24\n",
        "real_sample=24\n",
        "no_contrib=55"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def init_model():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    base_model = applications.DenseNet201(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    for layer in base_model.layers: #make the layers untrainable to get only the embeddings from the model output\n",
        "      layer.trainable = False\n",
        "\n",
        "    add_model = Sequential()\n",
        "    add_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
        "    add_model.add(Dense(256, activation='relu'))\n",
        "    add_model.add(Dense(2, activation='sigmoid'))\n",
        "    model = Model(inputs=base_model.input, outputs=add_model(base_model.output))\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
        "              metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "9acuxyC04lVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(train_fake_path, 'rb') as f:\n",
        "    fake=np.load(f)\n",
        "with open(train_real_path, 'rb') as f:\n",
        "    real=np.load(f)\n",
        "with open(syn_fake_path, 'rb') as f:\n",
        "    syn_fake=np.load(f)"
      ],
      "metadata": {
        "id": "-A1ZSPB-MOFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_generate(index,syn=False):\n",
        "  train_features = []\n",
        "  train_labels = []\n",
        "  test_features = []\n",
        "  test_labels = []\n",
        "  skil_features = []\n",
        "  skil_labels = []\n",
        "  syn_fake_features = []\n",
        "  syn_fake_labels = []\n",
        "  syn_skil_features = []\n",
        "  syn_skil_labels = []\n",
        "  #labels for train real\n",
        "  for j in range (0,real_sample * 2 // 3):\n",
        "      train_features.append(real[index*real_sample+j])\n",
        "      train_labels.append(1)\n",
        "  #labels for train fake\n",
        "  for j in range (0,fake_sample * 2 // 3):\n",
        "      train_features.append(fake[index*fake_sample+j])\n",
        "      train_labels.append(0)\n",
        "  #labels for test real\n",
        "  for j in range (real_sample * 2 // 3,real_sample) :\n",
        "      test_features.append(real[index*real_sample+j])\n",
        "      test_labels.append(1)\n",
        "  #labels for test fake\n",
        "  for j in range (fake_sample * 2 // 3,fake_sample) :\n",
        "      test_features.append(fake[index*fake_sample+j])\n",
        "      test_labels.append(0)\n",
        "  if syn:\n",
        "    for i in range(fake_sample * 2 // 3,fake_sample):\n",
        "      for j in range(9):\n",
        "        syn_fake_features.append(syn_fake[index*fake_sample*9+i*9+j])\n",
        "        syn_fake_labels.append(0)\n",
        "  #labels for test syn real\n",
        "  train_features = np.asarray(train_features).astype('float32')\n",
        "  test_features = np.asarray(test_features).astype('float32')\n",
        "  syn_fake_features = np.asarray(syn_fake_features).astype('float32')\n",
        "  #normalizing to from 0 to 1 by dividing with 255\n",
        "  train_features = train_features/ 255.\n",
        "  test_features = test_features / 255.\n",
        "  syn_fake_features = syn_fake_features /255.\n",
        "  train_labels = np.array(train_labels)\n",
        "  test_labels = np.array(test_labels)\n",
        "  syn_fake_labels = np.array(syn_fake_labels)\n",
        "  train_labels = to_categorical(train_labels)\n",
        "  return train_features,train_labels,test_features,test_labels,syn_fake_features,syn_fake_labels"
      ],
      "metadata": {
        "id": "OfzlxNc-3qzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_prediction(data,model):\n",
        "  tp = model.predict(data)\n",
        "  output=[]\n",
        "  for i in tp:\n",
        "    output.append(i[1])\n",
        "  return output"
      ],
      "metadata": {
        "id": "_0NBAEGXvSn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def acc(data,labels):\n",
        "  output =[]\n",
        "  for i in data:\n",
        "    if i>=0.5:\n",
        "      output.append(1)\n",
        "    else:\n",
        "      output.append(0)\n",
        "  return sklearn.metrics.accuracy_score(output,labels)"
      ],
      "metadata": {
        "id": "5USNkaY_Ia6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def far_frr_cal(data,compare): #function to calculate FAR and FRR based on 10 thresholds from 0 to 1\n",
        "  real = 0\n",
        "  fake = 0\n",
        "  frr = []\n",
        "  far =[]\n",
        "  for i in range (11):\n",
        "    frr.append(0)\n",
        "    far.append(0)\n",
        "  for i in range (len(data)):\n",
        "    if compare[i]==1:\n",
        "      real+=1\n",
        "    else:\n",
        "      fake+=1\n",
        "  for i in range (len(data)):\n",
        "    for j in range(11):\n",
        "      tp = 1\n",
        "      if data[i] <= j*0.1:\n",
        "        tp = 0\n",
        "      if tp!=compare[i]:\n",
        "        if compare[i]==0:\n",
        "          far[j]+=1\n",
        "        else:\n",
        "          frr[j]+=1\n",
        "  for i in range (11):\n",
        "    frr[i]/=real/100\n",
        "    far[i]/=fake/100\n",
        "  return [far,frr]\n",
        "\n",
        "def far_cal(data,compare):\n",
        "  far =[]\n",
        "  for i in range (11):\n",
        "    far.append(0)\n",
        "  for i in range (len(data)):\n",
        "    for j in range(11):\n",
        "      tp = 1\n",
        "      if data[i] <= j*0.1:\n",
        "        tp = 0\n",
        "      if tp==1:\n",
        "        far[j]+=1\n",
        "  for i in range (11):\n",
        "    far[i]/=len(data)/100\n",
        "  return far\n",
        "\n"
      ],
      "metadata": {
        "id": "fGSwqo76Jke8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_person(index):\n",
        "  y_test = []\n",
        "  y_label = []\n",
        "  train_features,train_labels,test_features,test_labels,syn_fake_features,syn_fake_labels = data_generate(index,True)\n",
        "  batch_size = 32\n",
        "  epochs = 100\n",
        "  model = init_model()\n",
        "  history = model.fit(train_features, train_labels, batch_size=batch_size,epochs=epochs,verbose=1)\n",
        "  human_test = make_prediction(test_features,model)\n",
        "  syn_fake_test = make_prediction(syn_fake_features,model)\n",
        "  y_test.extend(human_test)\n",
        "  y_test.extend(syn_fake_test)\n",
        "\n",
        "  y_label.extend(test_labels)\n",
        "  y_label.extend(syn_fake_labels)\n",
        "  return acc(human_test,test_labels), acc(syn_fake_test,syn_fake_labels),far_frr_cal(human_test,test_labels),far_cal(syn_fake_test ,syn_fake_labels),human_test,test_labels, y_test, y_label"
      ],
      "metadata": {
        "id": "6bLEPxUCUG7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = []\n",
        "y_label = []\n",
        "human_test = []\n",
        "human_label = []"
      ],
      "metadata": {
        "id": "6bA1qr-B2JDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "human_frr = []\n",
        "for i in range (11):\n",
        "  human_frr.append(0)\n",
        "human_far = []\n",
        "for i in range (11):\n",
        "  human_far.append(0)\n",
        "syn_real_far = []\n",
        "for i in range (11):\n",
        "  syn_real_far.append(0)\n",
        "syn_fake_far = []\n",
        "for i in range (11):\n",
        "  syn_fake_far.append(0)\n",
        "human_test = []\n",
        "human_label = []\n",
        "with open(result_path,'w') as f:\n",
        "  writer = csv.writer(f)\n",
        "  writer.writerow([\"human_far\",\"human_frr\", \"synt_fake_far\"])\n",
        "  for i in range (no_contrib):\n",
        "    print('----------- evaluating person '+str(i+1)+'--------------')\n",
        "    a,b,x,z, humantest, humanlabel, ytest, ylabel = evaluate_person(i)\n",
        "    print(x[0][5],x[1][5],z[5])\n",
        "  f.close()"
      ],
      "metadata": {
        "id": "9Fi-FeL3YVuo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}